---
layout: post
title: LSTM'S on Domain Specific Languages - LSTM-DSL
category: posts
---

[Mid term checkpoint](http://parthchadha.github.io/posts/2017/04/10/mid_report_418.html)

[Final report Link](http://parthchadha.github.io/posts/2017/05/12/final_report.html)

##Team
1. Tejus S, AndrewID : tsiddaga
2. Parth Chadha, AndrewID: pchadha

## Summary
In the LSTM-DSL project, we aim to produce a high-performance implementation of Long-Short Term Memory Network using Domain-Specific Languages such as Halide and/or using custom DSL. This would provide portability across different platforms and architectures.

## Background
LSTM's are a variant of RNN and were designed to tackle the vanishing gradients problem with RNN. 
RNN's when back-propogated over a large number of time-steps, face a problem of diminished value of gradients. With the presence of memory cell in LSTM's, we can have continuous gradient flow which helps in learning long-term dependencies.
Equations describing LSTM network:

$$ i\_{t} = sigm(\theta\_{xi} X\_{t} + \theta\_{hi} h\_{t-1} + b\_{i}) $$

$$ f\_{t} = sigm(\theta\_{xf} X\_{t} + \theta\_{hf} h\_{t-1} + b\_{f}) $$

$$ o\_{t} = sigm(\theta\_{xo} X\_{t} + \theta\_{ho} h\_{t-1} + b\_{o})$$

$$ g_{t} = sigm(\theta\_{xg} X\_{t} + \theta\_{hg} h\_{t-1} + b\_{g}) $$

$$ c_{t} = f\_{t} \cdot c\_{t-1} + i\_{t} \cdot g\_{t} $$

$$ h_{t} = o\_{t} \cdot tanh(c\_{t-1}) $$

The cost involved in evaluating these networks is dominated by Matrix Matrix Multiplication operation, GEMM operation in BLAS libraries. A naive implementation would perform eight matrix-matrix multiplications, 4 with inputs and 4 with previous state vectors. We plan to explore various optimizations around the naive implementation such as Combining Operations, Fusing Point Wise operations etc.

We plan to initially get familiar with Halide and understand more in depth about Domain Specific Languages and understand the limitations of Halide in tasks not meant for Image Processing such as LSTM's. Based on our learning and as mentioned in suggested projects, we plan to implement a custom DSL to incorporate variants of RNN's in the framework. Using the DSL, we aim to use basic blocks from cuDNN or cuBLAS for effecient operations on matrices. 

## The Challenge
1. Since this is our introduction to Domain Specifc Languages, we assume the learning curve would be steep and hence we plan to initially spend some time to understand the code structure in Halide.

2. Training of LSTM's using Backpropogation Through Time is a tricky process and might take time to get the gradient calculations right. We can initially try to optimize just for inference using pre-trained network and if the time permits, optimize for backpropogation.

## Goals And Deliverables
###PLAN TO ACHIEVE
1. Implementing a custom DSL for LSTM's 
2. Evaluating the network using library interface from cuBLAS
3. The baseline will consist of running a seperate kernel for each matrix-matrix operation and not performing any optimization such as combination of operations, fusion of operations etc. We plan to freeze the network architecture and hyperparameters after getting a baseline working, and having comparison of optimized version with this network/hyperparameters. We will compare performance using TFLOPS achieved.
4. Optimize only for inference and using a pre-trained network

###HOPE TO ACHIEVE
1. Optimization of back-propogation through time and training deeper networks.
2. Performing hyper-parameter search and optimization to extract maximum parallelism from the underlying hardware

## Platform Choice
The GTX 1080 GPU's on GHC.

## Schedule
1. Week 1 - April 10th - 16th
    
    1. Go through Halide source code and learn more about DSL's and understand the limitations of Halide for the use of LSTM's.
    2. Have a in-depth understanding of LSTM's implementation 
    3. Meet with Ravi for discussion regarding the project plan

2. Week 2 - April 17th - 23rd
    1. Have a naive working code for LSTM inference
    2. Explore DSL's implementation and start implementing a mini-DSL using Python

3. Week 3 - April 24th - 30th

    1. Complete DSL implementation
    2. Explore cuBLAS and cuDNN library and possibly implement a naive basic block code generation
    
4. Week 4 - May 1st - 7th

    1. Test and benchmark the naive implementation
    2. Understand the existing bottlenecks in naive implementation
    3. Perform optimizations on the current implementation for speedup!
    
5. Week 5 - May 8th - 12th
    1. Perform more optimizations and achieve more speedup!
    2. Documentation
    3. If time permits, optimizing for back-propogation and train a network.

##References
1. Optimizing Performance of Recurrent Neural Networks on GPUs
    Link : https://arxiv.org/abs/1604.01946
2. https://devblogs.nvidia.com/parallelforall/  optimizing-recurrent-neural-networks-cudnn-5/



 